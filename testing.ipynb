{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bb3f9bc-1875-4fb4-83f0-f3e34fefe02d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Dict, List, Any\n",
    "from airops.defaults import make_chain, make_agent\n",
    "\n",
    "\n",
    "with open('./context/workflow_spec.md', 'r') as f:\n",
    "    WORKFLOW_SPEC = f.read()\n",
    "\n",
    "with open('./context/integration_actions.json', 'r') as f:\n",
    "    INTEGRATION_ACTIONS = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50baaab8-56b6-40cc-b3dd-bbd5b979829c",
   "metadata": {},
   "outputs": [],
   "source": [
    "available_integrations = sorted([{\n",
    "    'integration': ia['integration'], \n",
    "    'action': ia['action'], \n",
    "} for ia in INTEGRATION_ACTIONS], key = lambda x: x['integration'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a02a3d-c4e1-4dfd-867c-8b2d9b5e573d",
   "metadata": {},
   "source": [
    "I do not understand what all of these integrations do and what fields are required and I don't need to. The agent/LLM is going to take care of that. All you need to do is generate relatively straightforward workflows, then ask an LLM to generate synthetic user requests for integrations that are applicable to the workflow. In the test case, you should include the desired integration selection for the input (use this for the evaluation).\n",
    "\n",
    "Question: how do I evaluate that the payload is correct?\n",
    "\n",
    "3 test steps:\n",
    "1. check that the chosen integration is correct (simple pass or fail)\n",
    "2. check that the payload matches the input schema for the integration (simple pass or fail)\n",
    "3. check that the choices for the payload values makes sense given the user's request (GEval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4723bf1-7c28-429f-a91c-deb201463be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(available_integrations, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0562ac30-5de5-4d62-bcbd-266722fccaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_cases_from_context(context: Dict, num_requests: 5):\n",
    "    # use an agent to create test cases - the agent will research what each action does to understand it\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a42282-110a-444c-94b3-ea063e19e953",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "airops",
   "language": "python",
   "name": "airops"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
