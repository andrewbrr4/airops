{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb3f9bc-1875-4fb4-83f0-f3e34fefe02d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from airops.defaults import make_chain, make_agent\n",
    "from airops import models, prompts\n",
    "from airops.tools import get_action_details, tavily_search, tavily_extract\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Dict, List, Any\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from openai import RateLimitError\n",
    "from langfuse.decorators import observe, langfuse_context\n",
    "from langfuse.callback import CallbackHandler\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "\n",
    "\n",
    "with open('./context/workflow_spec.md', 'r') as f:\n",
    "    WORKFLOW_SPEC = f.read()\n",
    "\n",
    "with open('./context/integration_actions.json', 'r') as f:\n",
    "    INTEGRATION_ACTIONS = sorted(json.load(f), key = lambda x: x['integration'])\n",
    "    for action in INTEGRATION_ACTIONS:\n",
    "        action[\"inputs_schema\"] = [field for field in action[\"inputs_schema\"] if field[\"interface\"] != \"integration\"]\n",
    "\n",
    "AVAILABLE_INTEGRATION_ACTIONS = [{'integration': ia['integration'], 'action': ia['action']} for ia in INTEGRATION_ACTIONS]\n",
    "\n",
    "SAMPLE_WORKFLOW_CONTEXTS = []\n",
    "for file in os.listdir('./context/sample_workflows/'):\n",
    "    fp = os.path.join('./context/sample_workflows/', file)\n",
    "    with open(fp, 'r') as file:\n",
    "        SAMPLE_WORKFLOW_CONTEXTS.append(json.load(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e8a474-0f30-4fac-badb-a8c00276ac0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@observe()\n",
    "def create_test_case(integration_action, sample_context):\n",
    "    try:\n",
    "        create_test_case_agent = make_agent(\n",
    "            tools = [get_action_details, tavily_search, tavily_extract],\n",
    "            prompt_template = prompts.CREATE_TEST_CASE_PROMPT,\n",
    "            output_model = models.TestCase,\n",
    "            llm='gpt-4.1-mini'\n",
    "        )\n",
    "        langfuse_handler = langfuse_context.get_current_langchain_handler()\n",
    "        results = create_test_case_agent.invoke({\n",
    "            \"workflow_context\": sample_context,\n",
    "            \"integration\": integration_action[\"integration\"],\n",
    "            \"action\": integration_action[\"action\"],\n",
    "        }, config={\"callbacks\": [langfuse_handler]})\n",
    "        return {\n",
    "            **integration_action,\n",
    "            'context': sample_context,\n",
    "            **results.model_dump()\n",
    "        }\n",
    "    except RateLimitError as e:\n",
    "        time.sleep(60)\n",
    "        return create_test_case(integration_action, sample_context)\n",
    "    except Exception as e:\n",
    "        print(f'Error: {e}')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2af4362-1d6c-4a52-bc1e-367fc57ee64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_cases(target_fp):\n",
    "    if os.path.exists(target_fp):\n",
    "        return joblib.load(target_fp)\n",
    "    test_cases = []\n",
    "    for action in tqdm(AVAILABLE_INTEGRATION_ACTIONS, desc=\"Actions\"):\n",
    "        futures = []\n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            for sample in SAMPLE_WORKFLOW_CONTEXTS:\n",
    "                futures.append(executor.submit(create_test_case, action, sample))\n",
    "            for f in as_completed(futures):\n",
    "                result = f.result()\n",
    "                if result is not None:\n",
    "                    test_cases.append(result)\n",
    "    joblib.dump(test_cases, target_fp)\n",
    "    return test_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace764ff-9eb6-408b-bbf6-8cb481ea73ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cases = create_test_cases('./eval/test_cases.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92641da7-c2f0-494b-b8ed-ac5725946830",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cases[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3783ae28-1992-4526-a7bb-ef7c791dd5aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "airops",
   "language": "python",
   "name": "airops"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
